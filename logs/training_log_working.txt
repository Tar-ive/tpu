============================================================
POWER GRID RL TRAINING ON TPU
============================================================
JAX version: 0.6.2
Devices: 4 x TPU v4
============================================================
Creating configuration...
Getting JAX devices...
Actor devices: [TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(1,0,0), core_on_chip=0)]
Learner devices: [TpuDevice(id=2, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,1,0), core_on_chip=0)]
Creating environment factory...
Creating pipeline...
Initializing multi-agent model...
Model initialized!
Exception in thread GridRLLearner:
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/home/tarive/persistent_storage/tpu_rl_workspace/grid_rl/train_grid_rl_tpu.py", line 47, in run
    self._run()
  File "/home/tarive/persistent_storage/tpu_rl_workspace/grid_rl/train_grid_rl_tpu.py", line 470, in _run
    self.state, metrics = self.update_fn(self.state, batch)
ValueError: pmap got inconsistent sizes for array axes to be mapped:
  * most axes (640 of them) had size 64, e.g. axis 0 of argument batch['actions'][0] of type int32[64,145];
  * some axes (383 of them) had size 2, e.g. axis 0 of argument state.step of type int32[2]

Starting training components...
Training with 2 actors and 1 learner
Total parallel environments: 128
------------------------------------------------------------

Stopping training components...

Training time: 0.00 hours
============================================================
